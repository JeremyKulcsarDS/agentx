{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Composition of agents as tool\n",
    "\n",
    "Agents and hierarchy of agents, easily implemented with AutoGen, can create powerful abstraction and enable high degree of resuability.\n",
    "\n",
    "In this example, we will create a multi-agent group chat to search for ETFs that satisfy a given investment direction and risk profile. There will be three agents:\n",
    "- `user_proxy` will ask for relevant ETFs that satisfy an investment direction and risk profile\n",
    "- `etf_retriever` will be equipped with the tool we created above.\n",
    "- `risk_evaluator` will evaluate risk level of each of the proposed ETFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "from xentropy.tool import Tool\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import autogen\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def termination(x):\n",
    "    return x.get('name') == 'risk_evaluator'\n",
    "\n",
    "# Load the etf search tool\n",
    "# Check out how this tool is created in docs/rag-tool\n",
    "etf_search = Tool.load('xentropy--etf_search', api_key=os.environ.get('XENTROPY_API_KEY'))\n",
    "\n",
    "# we need more context length to complete this example\n",
    "config_list = autogen.config_list_from_models(\n",
    "    model_list=[\"gpt-35-16\"],\n",
    ")\n",
    "\n",
    "llm_config = {\n",
    "    \"functions\": [\n",
    "        # added the new tool here\n",
    "        {\n",
    "            \"name\": etf_search.name,\n",
    "            \"description\": etf_search.description,\n",
    "            \"parameters\": etf_search.input_model_schema(),\n",
    "        },\n",
    "    ],\n",
    "    \"config_list\": config_list,\n",
    "    \"request_timeout\": 120,\n",
    "}\n",
    "\n",
    "# Construct the agent with the new config\n",
    "etf_researcher = autogen.AssistantAgent(\n",
    "    name=\"etf_researcher\",\n",
    "    system_message=\"You are an export in ETF research. You can use the functions you have been provided with.\",\n",
    "    llm_config=llm_config,\n",
    "    max_consecutive_auto_reply=3,\n",
    "    function_map={\n",
    "        etf_search.name: etf_search.run,\n",
    "    },\n",
    "    is_termination_msg=termination\n",
    ")\n",
    "\n",
    "\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    system_message=\"Reply TERMINATE when the task is done.\",\n",
    "    max_consecutive_auto_reply=3,\n",
    "    llm_config={\n",
    "        \"config_list\": config_list,\n",
    "    },\n",
    "    is_termination_msg=termination\n",
    ")\n",
    "\n",
    "risk_evaluator = autogen.AssistantAgent(\n",
    "    name=\"risk_evaluator\",\n",
    "    system_message=\"You are a risk management expert and specialise in evaluating risk associated with ETFs.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=3,\n",
    "    llm_config={\n",
    "        \"config_list\": config_list,\n",
    "    },\n",
    "    is_termination_msg=termination\n",
    ")\n",
    "\n",
    "groupchat = autogen.GroupChat(\n",
    "    func_call_filter=True,\n",
    "    agents=[user_proxy, etf_researcher, risk_evaluator],\n",
    "    messages=[],\n",
    "    max_round=12\n",
    ")\n",
    "manager = autogen.GroupChatManager(\n",
    "    groupchat=groupchat,\n",
    "    llm_config=llm_config,\n",
    "    is_termination_msg=termination\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_proxy.initiate_chat(\n",
    "    manager,\n",
    "    message=f\"\"\"Search ETFs that invest in semiconductor. \n",
    "Evaluate the result by its risk level. \n",
    "Then, create a report to compare their historical performance and analysis their risk level.\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class ETFReport(BaseModel):\n",
    "    name:str\n",
    "    industry:str\n",
    "    symbol:str\n",
    "    expense_ratio:float\n",
    "    volitility:str\n",
    "    risk_exposure:str\n",
    "    top_holdings:List[str]\n",
    "    performance:Dict\n",
    "\n",
    "class ETFReportList(BaseModel):\n",
    "    result:List[ETFReport]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a structured output will ease integration with other systems\n",
    "\n",
    "import json\n",
    "from autogen import OpenAIWrapper\n",
    "\n",
    "client = OpenAIWrapper(config_list=config_list)\n",
    "\n",
    "conversation = json.dumps(list(manager.chat_messages.items())[0][1])\n",
    "\n",
    "schema = ETFReportList.model_json_schema()\n",
    "\n",
    "def extract_json_body(client, model, conversation, num_try):\n",
    "    iteration = 0\n",
    "\n",
    "    while iteration < num_try:\n",
    "\n",
    "        raw_text = client.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    'role':'user',\n",
    "                    'content':f\"You will return a JSON object according this json schema: {schema} \\n\\n Based on the following conversation:{conversation} \\n\\nReturn the JSON object only.\",\n",
    "                }\n",
    "            ],\n",
    "        ).choices[0].message.content\n",
    "\n",
    "        try:\n",
    "            return model.model_validate_json(raw_text)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    raise Exception()\n",
    "\n",
    "\n",
    "result = extract_json_body(client, ETFReportList, conversation, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rich_print\n",
    "\n",
    "rich_print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A* Chat\n",
    "\n",
    "As your application grows bigger, you may want to create more than one agent, each with a different set of tools to handle different part of the problem. Orchestrating a conversation between these agents can be challenging, especially when it is difficult to determind which agent should be called at each timestep.\n",
    "\n",
    "Seeing multi-agent chat as a path finding problem, where each message in a message history is analogous to a node, and the message history as the path, A* algorithm can be used to find the optimal path to the end of the conversation.\n",
    "\n",
    "A* algorithm is a path finding algorithm that is widely used. It is a variant of Dijkstra's algorithm, which is used to find the shortest path between two nodes in a graph. A* algorithm is an extension of Dijkstra's algorithm, which adds a heuristic function to guide the search towards the goal. The heuristic function is an estimation of the distance between the current node and the goal. The algorithm will always choose the node with the lowest cost, which is the sum of the distance from the start node to the current node and the heuristic function.\n",
    "\n",
    "Using A* Chat, instead of having to manually program agent behaviours, you can simply define the heuristic function that estimates how *close* the message history to the goal, and the algorithm will automatically orchestrate the conversation between the agents to reach the goal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 0: A* Chat to write test problems and solutions according to Bloom’s Taxonomy of Educational Objectives\n",
    "We will use A* Chat to orchestrate a conversation between a two agents:\n",
    "- test_giver: writes a set of questions and marking scheme about a subject\n",
    "- bloom: apply [Bloom’s Taxonomy of Educational Objectives](https://en.wikipedia.org/wiki/Bloom%27s_taxonomy#:~:text=Bloom's%20taxonomy%20is%20a%20set,cognitive%2C%20affective%20and%20psychomotor%20domains.) to evaluate the quality of the test problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agentx.agent import Agent\n",
    "from agentx.schema import GenerationConfig, Message, Content\n",
    "from agentx.astar import astarchat, reconstruct_path\n",
    "from agentx.tool import Tool\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Dict, List, Literal\n",
    "from functools import partial\n",
    "from dotenv import load_dotenv\n",
    "from rich import print as rich_print\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "generation_config = GenerationConfig(\n",
    "    api_type='azure',\n",
    "    api_key=os.environ.get('AZURE_OPENAI_KEY'),\n",
    "    base_url=os.environ.get('AZURE_OPENAI_ENDPOINT'),\n",
    "    azure_deployment='gpt-35',\n",
    ")\n",
    "\n",
    "# this agent will write the question / answer pair\n",
    "test_writer = Agent(\n",
    "    name='test_writer',\n",
    "    generation_config=generation_config,\n",
    "    system_prompt='''According to the user request and feedback, write a test question / answer pair.''',\n",
    ")\n",
    "\n",
    "class TestQuestion(BaseModel):\n",
    "    question:str\n",
    "    answer:str\n",
    "\n",
    "# Define agents and tools for reviewing the test question\n",
    "bloom = Agent(\n",
    "    name='bloom_expert',\n",
    "    generation_config=generation_config,\n",
    "    system_prompt=\"You are an education expert and highly knowledgeable about Bloom's taxonomy of education objective.\",\n",
    ")\n",
    "\n",
    "class BloomScore(BaseModel):\n",
    "    score:float = Field(0, ge=0, le=10),\n",
    "    improvement_suggestion:str\n",
    "    objective:Literal['knowledge', 'comprehension', 'application', 'analysis', 'synthesis', 'evaluation']\n",
    "\n",
    "class BloomScorer(Tool):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        agent:Agent,\n",
    "        bloom_objective:Literal['knowledge', 'comprehension', 'application', 'analysis', 'synthesis', 'evaluation'],\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.agent = agent\n",
    "        self.bloom_objective = bloom_objective\n",
    "\n",
    "    def run(self, **kwargs) -> str:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    async def arun(self, **kwargs) -> str:\n",
    "        test_question = TestQuestion(**kwargs)\n",
    "        response = await self.agent.a_generate_response(\n",
    "            messages=[\n",
    "                Message(\n",
    "                    role='user',\n",
    "                    content=Content(\n",
    "                        text='''Please give a score of 10 to represent the test question's quality at the {bloom_objective} level of Bloom's Taxonomy.\n",
    "The test question:\n",
    "{test_question}\n",
    "\n",
    "You must reply an JSON object.'''.format(\n",
    "    bloom_objective=self.bloom_objective,\n",
    "    test_question=test_question.model_dump()\n",
    "),\n",
    "                    ),\n",
    "                )\n",
    "            ],\n",
    "            output_model=BloomScore\n",
    "        )\n",
    "        return response.content.text\n",
    "\n",
    "bloom_scoring_tools = [\n",
    "    BloomScorer(\n",
    "        bloom,\n",
    "        bloom_objective,\n",
    "        name='{bloom_objective}_scorer'.format(bloom_objective=bloom_objective),\n",
    "        description='''Give a score of 10 to represent that the test question is at the {bloom_objective} level of Bloom's Taxonomy and the question's quality.'''.format(bloom_objective=bloom_objective),\n",
    "        input_json_schema=TestQuestion.model_json_schema(),\n",
    "    ) for bloom_objective in ['knowledge', 'comprehension', 'application', 'analysis', 'synthesis', 'evaluation']\n",
    "]\n",
    "\n",
    "# this agent will review the question / answer pair\n",
    "reviewer = Agent(\n",
    "    name='reviewer',\n",
    "    generation_config=generation_config,\n",
    "    system_prompt='''Use the tool you have been provided to review the question. Critically access if the test question is at the right level and quality of Bloom's Taxonomy. If not, give feedback on how to improve the question.''',\n",
    "    tools=bloom_scoring_tools,\n",
    ")\n",
    "\n",
    "# At each timestep, A* minimize heuristic + cost\n",
    "# heuristic: an estimation of the distance between the current state and the goal state\n",
    "# cost: the distance between the start state and the current state\n",
    "\n",
    "# Heuristic is the sum of the difference between the current Bloom score and the target Bloom score\n",
    "class BloomReport(BaseModel):\n",
    "    knowledge:float = Field(0, ge=0, le=10)\n",
    "    comprehension:float = Field(0, ge=0, le=10)\n",
    "    application:float = Field(0, ge=0, le=10)\n",
    "    analysis:float = Field(0, ge=0, le=10)\n",
    "    synthesis:float = Field(0, ge=0, le=10)\n",
    "    evaluation:float = Field(0, ge=0, le=10)\n",
    "\n",
    "extractor = Agent(\n",
    "    name='extractor',\n",
    "    generation_config=generation_config,\n",
    "    system_prompt='''Extract the latest Bloom score from the messages history. You must reply an JSON object.''',\n",
    ")\n",
    "\n",
    "def heuristic(\n",
    "    messages:List[Message], \n",
    "    target:Dict[Literal['knowledge', 'comprehension', 'application', 'analysis', 'synthesis', 'evaluation'], float]\n",
    ") -> float:\n",
    "    if 'test_writer' not in [message.name for message in messages]:\n",
    "        # no test question has been written\n",
    "        return 10\n",
    "    if 'reviewer' not in [message.name for message in messages]:\n",
    "        # no review has been made\n",
    "        return 10\n",
    "    if not messages[-1].name in [f'{bloom_objective}_scorer' for bloom_objective in ['knowledge', 'comprehension', 'application', 'analysis', 'synthesis', 'evaluation']]:\n",
    "        # heuristic only applies when the last message is a Bloom scorer\n",
    "        return None\n",
    "    \n",
    "    bloom_report = extractor.generate_response(\n",
    "        messages=[\n",
    "            Message(\n",
    "                role='user',\n",
    "                content=Content(\n",
    "                    text='Based on this chat history: {history}'.format(\n",
    "                        history=[message.model_dump_json(\n",
    "                            exclude_unset=True,\n",
    "                            exclude_none=True\n",
    "                        ) for message in messages]\n",
    "                    ),\n",
    "                ),\n",
    "            )\n",
    "        ] + [\n",
    "            Message(\n",
    "                role='user',\n",
    "                content=Content(\n",
    "                    text='Extract the latest Bloom scores. You must reply an JSON object.'),\n",
    "            ),\n",
    "        ],\n",
    "        output_model=BloomReport,\n",
    "    ).content.text\n",
    "    bloom_report = BloomReport.model_validate_json(bloom_report).model_dump()\n",
    "    \n",
    "    # print out for easier debugging and illustration\n",
    "    rich_print([message for message in messages if message.name=='test_writer'][-1].content.text)\n",
    "    rich_print(bloom_report)\n",
    "\n",
    "    difference = sum(\n",
    "        [\n",
    "            abs(bloom_report[objective] - target[objective]) for objective in ['knowledge', 'comprehension', 'application', 'analysis', 'synthesis', 'evaluation']\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return difference / sum(target.values()) * 10\n",
    "\n",
    "# Cost is the number of LLM calls\n",
    "def cost(messages:List[Message], next_message:List[Message]) -> float:\n",
    "    cost = len(next_message)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Question: Which of the following best represents an example of Mendelian Genetics?\n",
       "\n",
       "a<span style=\"font-weight: bold\">)</span> A child inheriting the trait for attached earlobes from their parents\n",
       "b<span style=\"font-weight: bold\">)</span> A child inheriting the ability to roll their tongue from their parents\n",
       "c<span style=\"font-weight: bold\">)</span> A child inheriting the skill for playing musical instruments from their parents\n",
       "d<span style=\"font-weight: bold\">)</span> A child inheriting the habit of nail-biting from their parents\n",
       "\n",
       "Answer: a<span style=\"font-weight: bold\">)</span> A child inheriting the trait for attached earlobes from their parents\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Question: Which of the following best represents an example of Mendelian Genetics?\n",
       "\n",
       "a\u001b[1m)\u001b[0m A child inheriting the trait for attached earlobes from their parents\n",
       "b\u001b[1m)\u001b[0m A child inheriting the ability to roll their tongue from their parents\n",
       "c\u001b[1m)\u001b[0m A child inheriting the skill for playing musical instruments from their parents\n",
       "d\u001b[1m)\u001b[0m A child inheriting the habit of nail-biting from their parents\n",
       "\n",
       "Answer: a\u001b[1m)\u001b[0m A child inheriting the trait for attached earlobes from their parents\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'knowledge'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'comprehension'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10.0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'application'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'analysis'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'synthesis'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'evaluation'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'knowledge'\u001b[0m: \u001b[1;36m7.0\u001b[0m, \u001b[32m'comprehension'\u001b[0m: \u001b[1;36m10.0\u001b[0m, \u001b[32m'application'\u001b[0m: \u001b[1;36m0.0\u001b[0m, \u001b[32m'analysis'\u001b[0m: \u001b[1;36m0.0\u001b[0m, \u001b[32m'synthesis'\u001b[0m: \u001b[1;36m0.0\u001b[0m, \u001b[32m'evaluation'\u001b[0m: \u001b[1;36m0.0\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# notice how the target is iteratively reached\n",
    "\n",
    "target = {'knowledge': 10, 'comprehension': 5, 'application': 0, 'analysis': 0, 'synthesis': 0, 'evaluation': 0}\n",
    "init_message = Message(\n",
    "    role = 'user',\n",
    "    content = Content(\n",
    "        text = '''According to the target {target}, write a multiple choice test question / answer pair about Mendelian Genetics'''.format(\n",
    "            target=target\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "reconstructed_path, came_from, cost_so_far, heuristic_map, hash_map = await astarchat(\n",
    "    agents = [test_writer, reviewer],\n",
    "    heuristic = partial(heuristic, target=target),\n",
    "    cost = cost,\n",
    "    messages = [init_message],\n",
    "    threshold = 2,\n",
    "    n_replies = 1,\n",
    "    max_iteration = 10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
